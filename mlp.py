# -*- coding: utf-8 -*-
"""MLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11bMHuqTVulU2XH7_2GWQ-u14hBHSl1Vd
"""

import torchvision.datasets as dataset
import torchvision.transforms as transform

mnist_train = dataset.MNIST(root="./dataset/", train=True, transform=transform.ToTensor(), download=True)
mnist_test = dataset.MNIST(root="./dataset/", train=False, transform=transform.ToTensor(), download=True)

cifar10_train = dataset.CIFAR10(root="./dataset/",train=True, transform=transform.ToTensor(), download=True)
cifar10_test = dataset.CIFAR10(root="./dataset", train=False, transform=transform.ToTensor(), download=True)





import matplotlib.pyplot as plt

print(len(mnist_train))

first_dataset=mnist_train[0]
print(first_dataset[0].shape)
print(first_dataset[1])
plt.imshow(first_dataset[0][0,:,:],cmap="gray")
plt.show()

import torch
import torch.nn as nn
import torchvision.datasets as dataset
import torchvision.transforms as transform
from torch.utils.data import DataLoader

mnist_train = dataset.MNIST(root="./dataset/",
                           train=True,
                           transform=transform.ToTensor(),
                           download=True)

mnist_test = dataset.MNIST(root="./dataset/",
                          train=False,
                          transform=transform.ToTensor(),
                          download=True)

class SLP(nn.Module):
    def __init__(self):
        super (SLP,self).__init__()
        self.fc = nn.Linear(in_features=784,out_features=10)
        
    def forward(self,x):
        out = self.fc(x)
        return out

batch_size = 100
learning_rate=0.1
training_epochs = 15
loss_function = nn.CrossEntropyLoss()
network = SLP()
optimizer = torch.optim.SGD(network.parameters(), lr = learning_rate)

data_loader =DataLoader(dataset=mnist_train,
                       batch_size = batch_size,
                       shuffle=True,
                       drop_last=True)

for epoch in range(training_epochs):
    avg_cost =0
    total_batch = len(data_loader)
    for img, label in data_loader:
        img= img.view(-1,28*28)

        pred = network(img)

        loss = loss_function(pred, label)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        avg_cost += loss / total_batch
    print("Epoch:%d Loss = %f"%(epoch+1, avg_cost))
torch.save(network.state_dict(),"./slp_mnist.pth")
print("Learning finished")

with torch.no_grad():
    img_test=mnist_test.data.view(-1,28*28).float()
    label_test = mnist_test.targets
    
    prediction = network(img_test)
    correct_prediction = torch.argmax(prediction, 1) == label_test
    accuracy = correct_prediction.float().mean()
    print("Accuracy:",accuracy.item())

class MLP(nn.Module):
  def __init__(self):
    super(MLP, self).__init__()
    self.fc1=nn.Linear(in_features=784, out_features=100)
    self.fc2=nn.Linear(in_features=100,out_features=10)
    self.sigmoid = nn.Sigmoid()

  def forward(self,x):
    out = self.sigmoid(self.fc1(x))
    out = self.fc2(out)
    return out

network = MLP()
optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate)

for epoch in range(training_epochs):
  avg_cost = 0
  total_batch = len(data_loader)
  for img, label in data_loader:
    img = img.view(-1,28*28)

    pred = network(img)

    loss = loss_function(pred, label)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    avg_cost +=loss/total_batch
  print("Epoch:%d Loss =%f"%(epoch+1, avg_cost))
torch.save(network.state_dict(),"./mlp_mnist.pth")
print("Learning finished")

network = MLP()
network.load_state_dict(torch.load("./mlp_mnist.pth"))

with torch.no_grad():
  img_test = mnist_test.data.view(-1, 28*28).float()
  label_test = mnist_test.targets

  prediction = nextwork(img_test)
  correct_prediction = torch.atgmax(prediction,1)==label_test
  accuracy = correct_prediction.float().mean()
  print("Accuracy:", accuracy.item())