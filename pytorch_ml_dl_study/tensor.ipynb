{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57867a08-7080-4e40-9e0f-cb3f34461417",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tensor는 행렬이나 배열과 매우 유사한 특수한 자료구조이다.\n",
    "pytorch에서는 tensor를 사용하여 모델의 입력과 출력 그리고 모델의 매개변수들을 부호화한다.\n",
    "'''\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "414b88cb-e5a6-4ad6-b3e2-0fe6238c7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "torsor 초기화\n",
    "'''\n",
    "# 1. 데이터로 부터 직접생성하기 / 데이터로부터 직접 텐서를 생성할 수 잇습니다. 데이터의 type은 자동으로 결정된다.\n",
    "data=[[1,2],[3,4]]\n",
    "x_data=torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d85d7872-8188-4bcd-91dd-42da5d64ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Numpy배열로부터 생성하기 / tensor는 Numpy배열로 생성할 수 있다.\n",
    "np_array=np.array(data)\n",
    "x_np=torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c4a4865-513c-4016-bef4-ba2866595fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 다른 tensor로부터 생성하기 / 명시적으로 재정의하지 않는다면, 인자로 주어진 텐서의 속성을 유지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e5e4405-f6dc-4154-b530-3d65287e52be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor : \n",
      " tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "\n",
      "Random Tensor : \n",
      " tensor([[0.6580, 0.3976],\n",
      "        [0.7194, 0.6359]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # x_data의 속성을 유지합니다.\n",
    "print(f\"Ones Tensor : \\n {x_ones}\\n\")\n",
    "\n",
    "x_rand=torch.rand_like(x_data, dtype=torch.float) # x-data의 속서을 덮어씁니다.\n",
    "print(f\"Random Tensor : \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0576d85-281c-41dd-b6d3-6a229c44787f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor의 속성\\n텐서의 속성은 텐서의 모양 자료형 및 어느장치에 저장되는지를 나타냅니다.\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Tensor의 속성\n",
    "텐서의 속성은 텐서의 모양 자료형 및 어느장치에 저장되는지를 나타냅니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85cf92b7-16db-4f57-a8f9-174371b50136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor : torch.Size([3, 4])\n",
      "Datatype of tensor:torch.float32\n",
      "Device tensor is stored on : cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "print(f\"Shape of tensor : {tensor.shape}\")\n",
    "print(f\"Datatype of tensor:{tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on : {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35bb3b07-4bae-4631-9165-c4280d4ee29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntensor operation\\n전치(transposing),인덱싱(indexing),슬라이싱(slicing),수학계산, 선형대수, 임의 샘플링(random sampling)등 100가지 이상의 텐서 연산들은 일반적으로 cpu보다 빠른\\nGPU에서 실행할 수 있습니다. 기본적으로 텐서는 cpu에 생성됩니다. .to메소드를 사용하면 gpu로 텐서를 명시적으로 이동할 수 있습니다. 장치들 간에 큰 텐서들을 복사하는\\n것은 시간과 메모리 측면에서 비용이 많이 든다는 것을 기억하세요!\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tensor operation\n",
    "전치(transposing),인덱싱(indexing),슬라이싱(slicing),수학계산, 선형대수, 임의 샘플링(random sampling)등 100가지 이상의 텐서 연산들은 일반적으로 cpu보다 빠른\n",
    "GPU에서 실행할 수 있습니다. 기본적으로 텐서는 cpu에 생성됩니다. .to메소드를 사용하면 gpu로 텐서를 명시적으로 이동할 수 있습니다. 장치들 간에 큰 텐서들을 복사하는\n",
    "것은 시간과 메모리 측면에서 비용이 많이 든다는 것을 기억하세요!\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7fe74bc9-4d4d-4e62-b171-24b78fddbd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU가 존재하면 텐서를 이동합니다.\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6940b095-8553-45ee-a3f7-2f43fc035106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "first row: tensor([1., 1., 1., 1.])\n",
      "first column tensor([1., 1., 1., 1.])\n",
      "last column tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4,4)\n",
    "print(tensor)\n",
    "print(\"first row:\", tensor[0])\n",
    "print(\"first column\", tensor[:,0])\n",
    "print(\"last column\", tensor[...,-1])\n",
    "tensor[:,1]=0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "65e42b9e-195f-4a55-ae5c-dfab6b247d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 합치기 torch.cat을 사용하여 주어진 차원에 따라 일련의 텐서를 연결할 수 있습니다. torch.cat과 미요하게 다른 또 다른 텐서 결합 연산인 torch.stack도 참고 바람\n",
    "# dim =0 : 아래위로 연결, dim=1 : 양옆으로 연결\n",
    "t1= torch.cat([tensor,tensor, tensor],dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f0996d6c-1d88-4c27-938a-5a8deb428ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 산술연산\n",
    "# 두 텐서 간의 형렬 곱(matrix multiplication)을 계산합니다. y1,y2,y3은 모두 같은 값을 갖습니다.\n",
    "y1 = tensor@tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3= torch. rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T,out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a42e78db-b487-491f-b77c-5eb22d5850f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요소별 곱(element-wise product)을 계산합니다. z1, z2, z3는 모두 같은 값을 갖습니다.\n",
    "z1=tensor * tensor\n",
    "z2=tensor.mul(tensor)\n",
    "\n",
    "z3=torch.rand_like(tensor)\n",
    "torch.mul(tensor,tensor,out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a7ee532a-aebb-4148-a4ea-199127c1b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일-요소(single-element)텐서 : 텐서의 모든 값을 하나로 집계(aggregate)하여 요소가 하니인 텐서의 경우,item()을 사용하여 python 숫자 값으로 변환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8443024a-1957-42da-a9fa-ae68f4210134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg=tensor.sum() # type = tensor\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "25b35225-c275-4d57-899b-ee30ea767f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# 바꿔치기(in-place)연산 연산결과를 피연산자(operand)에 저장하는 연산을바꿔치기 연산이라고 부르며, _접미사를 갖습니다. 예를들어:x,copy_(y)나x.t_()는 x를 변경한다.\n",
    "print(tensor,\"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc8526e-6e54-4ea1-afa8-ae760746011e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
